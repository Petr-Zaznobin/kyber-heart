{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ml_validation import database\n",
    "from ml_validation.experiment import three_bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_ALL, \"\")\n",
    "path_dataset = \"datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive already exists: datasets/three_bases.zip\n",
      "Archive already exists: datasets/three_bases_bad_records.zip\n"
     ]
    }
   ],
   "source": [
    "database.download(database.Type.THREE_BASES, path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Начинаем эксперимент\n",
    "experiment = three_bases.start_experiment(\n",
    "    name=\"DummyUniform\",\n",
    "    description=\"Тестовая загрузка данных базы 'Three bases'\",\n",
    "    authors=\"Moskalenko Viktor\",\n",
    "    path_dir=path_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54953, 12, 5000), (54953, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = experiment.get_data()\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# как найти количество обучаемых параметров на каждом слое\n",
    "class ECGCNN(nn.Module):\n",
    "    def __init__(self, input_channels=12, num_classes=5):\n",
    "        super(ECGCNN, self).__init__()\n",
    "        # Первый свёрточный блок\n",
    "        #padding-добавление нулей по бокам, stride-пропуск между kernels\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=32, kernel_size=9, padding=3, stride=1) #out:1249\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=4) #out:312\n",
    "\n",
    "        # Второй свёрточный блок\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=7, padding=2, stride=1) #out:155\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=4) #out:77\n",
    "\n",
    "        # Третий свёрточный блок\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding=1, stride=1) #out:18\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=4) #out: 4\n",
    "\n",
    "        # Второй свёрточный блок\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=7, padding=2, stride=1) #out:155\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=4) #out:77\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=32, kernel_size=9, padding=3, stride=1) #out:1249\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=4) #out:312\n",
    "\n",
    "        # Полносвязные слои с Dropout\n",
    "        self.fc1 = nn.Linear(128 * 4, 256)\n",
    "        self.dropout = nn.Dropout(p=0.2)  # Dropout с вероятностью 20%\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Первый свёрточный блок\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Второй свёрточный блок\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Третий свёрточный блок\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Преобразование для полносвязного слоя\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Полносвязные слои с Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Применение Dropout\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Преобразование меток\n",
    "Y = np.argmax(Y, axis=1)  # Преобразование one-hot в категории\n",
    "\n",
    "# Нормализация данных по каждому каналу\n",
    "X = (X - np.mean(X, axis=2, keepdims=True)) / np.std(X, axis=2, keepdims=True)\n",
    "\n",
    "# Разделение данных\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание Dataset\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, signals, labels):\n",
    "        self.signals = signals\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal = self.signals[idx]\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(signal, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "train_dataset = ECGDataset(X_train, Y_train)\n",
    "val_dataset = ECGDataset(X_val, Y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = ECGCNN(input_channels=12, num_classes=5)\\n#criterion = nn.CrossEntropyLoss()\\ncriterion = nn.BCELoss()\\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # Добавлен weight_decay\\n\\n# Тренировочный цикл\\nfor epoch in range(10):  # 20 эпох\\n    model.train()\\n    train_loss = 0.0\\n\\n    for signals, labels in train_loader:\\n        optimizer.zero_grad()\\n        outputs = model(signals)\\n        loss = criterion(outputs, labels)\\n        loss.backward()\\n        optimizer.step()\\n        train_loss += loss.item()\\n\\n    # Оценка на валидационной выборке\\n    model.eval()\\n    val_loss = 0.0\\n    correct = 0\\n    total = 0\\n\\n    with torch.no_grad():\\n        for signals, labels in val_loader:\\n            outputs = model(signals)\\n            loss = criterion(outputs, labels)\\n            val_loss += loss.item()\\n\\n            _, predicted = torch.max(outputs, 1)\\n            total += labels.size(0)\\n            correct += (predicted == labels).sum().item()\\n\\n    print(f\"Epoch {epoch+1}/{10}, Train Loss: {train_loss/len(train_loader):.4f}, \"\\n          f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\\n          f\"Val Accuracy: {100 * correct / total:.2f}%\")\\n\\n# Сохранение модели\\ntorch.save(model.state_dict(), \"ecg_cnn_weights_with_regularization_less_rank.pth\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализация модели, функции потерь и оптимизатора с L2-регуляризацией\n",
    "'''\n",
    "model = ECGCNN(input_channels=12, num_classes=5)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # Добавлен weight_decay\n",
    "\n",
    "# Тренировочный цикл\n",
    "for epoch in range(10):  # 20 эпох\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for signals, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(signals)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Оценка на валидационной выборке\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for signals, labels in val_loader:\n",
    "            outputs = model(signals)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{10}, Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "          f\"Val Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Сохранение модели\n",
    "torch.save(model.state_dict(), \"ecg_cnn_weights_with_regularization_less_rank.pth\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ECGCNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Инициализация модели, функции потерь и оптимизатора с L2-регуляризацией\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mECGCNN\u001b[49m(input_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# num_classes=5 для многоклассовой задачи\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#criterion = torch.nn.BCELoss()  # Бинарная кросс-энтропия\u001b[39;00m\n\u001b[1;32m      9\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ECGCNN' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Инициализация модели, функции потерь и оптимизатора с L2-регуляризацией\n",
    "model = ECGCNN(input_channels=12, num_classes=5)  # num_classes=5 для многоклассовой задачи\n",
    "#criterion = torch.nn.BCELoss()  # Бинарная кросс-энтропия\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # Добавлен weight_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x9856 and 512x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Прямой проход\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignals\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Sigmoid для приведения к диапазону [0, 1]\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Преобразование меток в one-hot\u001b[39;00m\n\u001b[1;32m     29\u001b[0m labels_one_hot \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(labels, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# [batch_size, num_classes]\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 55\u001b[0m, in \u001b[0;36mECGCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Полносвязные слои с Dropout\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     56\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)  \u001b[38;5;66;03m# Применение Dropout\u001b[39;00m\n\u001b[1;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x9856 and 512x256)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Списки для хранения значений на каждой эпохе\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "f1_scores = []\n",
    "\n",
    "# Тренировочный цикл\n",
    "for epoch in range(15):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for signals, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Прямой проход\n",
    "        outputs = torch.sigmoid(model(signals))  # Sigmoid для приведения к диапазону [0, 1]\n",
    "\n",
    "        # Преобразование меток в one-hot\n",
    "        labels_one_hot = F.one_hot(labels, num_classes=5).float()  # [batch_size, num_classes]\n",
    "        \n",
    "        # Вычисление функции потерь\n",
    "        loss = criterion(outputs, labels_one_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader))  # Сохраняем средний loss для трейна\n",
    "\n",
    "    # Оценка на валидационной выборке\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for signals, labels in val_loader:\n",
    "            #outputs = torch.sigmoid(model(signals))  # Sigmoid для диапазона [0, 1]\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=5).float()\n",
    "            \n",
    "            # Вычисление функции потерь\n",
    "            loss = criterion(outputs, labels_one_hot)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Для F1-score используем порог 0.5\n",
    "            predicted = (outputs > 0.5).int()  # Преобразуем вероятности в бинарные значения\n",
    "            all_labels.extend(labels_one_hot.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))  # Сохраняем средний loss для валидации\n",
    "\n",
    "    # Вычисление F1-score\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{15}, Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "          f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Построение графиков\n",
    "epochs = range(1, 16)\n",
    "\n",
    "# График зависимости Loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# График зависимости F1-score\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, f1_scores, label=\"F1 Score\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"F1 Score vs Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchinfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model – здесь указывается ваша PyTorch модель\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# input_size – размерность входного тензора для вашей модели\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m summary(\u001b[43mmodel\u001b[49m, input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "# model – здесь указывается ваша PyTorch модель\n",
    "# input_size – размерность входного тензора для вашей модели\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "torch.save(model.state_dict(), \"ecg_cnn_weights_with_regularization_bin_cross_entropy.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 эпох после роста лосса на валидации, чтобы чекать еще один минимум\n",
    "focal loss (модификация кросс-энтропии)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Patient ID in source database</th>\n",
       "      <th>Source database name</th>\n",
       "      <th>Index in source database</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Record index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15709.0</td>\n",
       "      <td>ptb_xl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13243.0</td>\n",
       "      <td>ptb_xl</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17014.0</td>\n",
       "      <td>ptb_xl</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17448.0</td>\n",
       "      <td>ptb_xl</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19005.0</td>\n",
       "      <td>ptb_xl</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age  Gender Patient ID in source database Source database name  \\\n",
       "Record index                                                                    \n",
       "0             56.0       0                       15709.0               ptb_xl   \n",
       "1             19.0       1                       13243.0               ptb_xl   \n",
       "3             24.0       1                       17014.0               ptb_xl   \n",
       "4             19.0       0                       17448.0               ptb_xl   \n",
       "5             18.0       0                       19005.0               ptb_xl   \n",
       "\n",
       "             Index in source database  \n",
       "Record index                           \n",
       "0                                   1  \n",
       "1                                   2  \n",
       "3                                   4  \n",
       "4                                   5  \n",
       "5                                   6  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = experiment.get_meta()\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /opt/homebrew/lib/python3.11/site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAlgorithm:\n",
    "    # Реализуем алгоритм диагностики\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Инициализация модели с загрузкой сохранённых весов.\n",
    "        \"\"\"\n",
    "        model_weights_path = '/Users/petrzaznobin/Desktop/High School/ROBO-HEART/ml_validation/ecg_cnn_weights_with_regularization_bin_cross_entropy.pth'\n",
    "        self.model = ECGCNN(input_channels=12, num_classes=5)\n",
    "        self.model.load_state_dict(torch.load(model_weights_path))\n",
    "        self.model.eval()  # Устанавливаем режим инференса\n",
    "\n",
    "    def __call__(self, X_test: npt.NDArray[np.float32]) -> npt.NDArray[np.bool_]:\n",
    "        \"\"\"\n",
    "        Применение модели для предсказания меток на тестовом наборе данных.\n",
    "\n",
    "        Parameters:\n",
    "        - X_test: Массив входных сигналов размерностью [N, 12, 5000].\n",
    "\n",
    "        Returns:\n",
    "        - Бинарный массив предсказаний размерностью [N, num_classes].\n",
    "        \"\"\"\n",
    "        # Преобразуем входные данные в тензор\n",
    "        inputs = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "        # Прогон данных через модель\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(inputs)\n",
    "\n",
    "        # Преобразуем логиты в вероятности\n",
    "        probabilities = F.softmax(logits, dim=1).numpy()\n",
    "\n",
    "        # Применяем пороговое значение 0.5 для бинарного вывода\n",
    "        predictions = probabilities > 0.5\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def print_weights(self):\n",
    "        print(torchsummary(model, input_size=(12, 5000), device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MyAlgorithm.print_weights of <__main__.MyAlgorithm object at 0x17ef79b50>>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyAlgorithm()\n",
    "model.print_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 32, 1250]           3,488\n",
      "       BatchNorm1d-2             [-1, 32, 1250]              64\n",
      "         MaxPool1d-3              [-1, 32, 312]               0\n",
      "            Conv1d-4              [-1, 64, 155]          14,400\n",
      "       BatchNorm1d-5              [-1, 64, 155]             128\n",
      "         MaxPool1d-6               [-1, 64, 38]               0\n",
      "            Conv1d-7              [-1, 128, 18]          41,088\n",
      "       BatchNorm1d-8              [-1, 128, 18]             256\n",
      "         MaxPool1d-9               [-1, 128, 4]               0\n",
      "           Linear-10                  [-1, 256]         131,328\n",
      "          Dropout-11                  [-1, 256]               0\n",
      "           Linear-12                    [-1, 5]           1,285\n",
      "================================================================\n",
      "Total params: 192,037\n",
      "Trainable params: 192,037\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.23\n",
      "Forward/backward pass size (MB): 0.90\n",
      "Params size (MB): 0.73\n",
      "Estimated Total Size (MB): 1.86\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mПри выполнении кода в текущей ячейке или предыдущей ячейке ядро аварийно завершило работу. \n",
      "\u001b[1;31mПроверьте код в ячейках, чтобы определить возможную причину сбоя. \n",
      "\u001b[1;31mЩелкните <a href='https://aka.ms/vscodeJupyterKernelCrash'>здесь</a>, чтобы получить дополнительные сведения. \n",
      "\u001b[1;31mПодробнее см. в <a href='command:jupyter.viewOutput'>журнале Jupyter</a>."
     ]
    }
   ],
   "source": [
    "from torchsummary import summary  # Correct way to import the summary function\n",
    "\n",
    "# Create an instance of MyAlgorithm and extract the model\n",
    "my_algorithm = MyAlgorithm()\n",
    "summary(my_algorithm.model, input_size=(12, 5000), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = experiment.validate(MyAlgorithm(), batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mВерсия\u001b[0m: 0.2.0\n",
      "\u001b[1mНачало\u001b[0m: Wed Dec 18 22:48:21 2024 MSK\n",
      "\u001b[1mКонец\u001b[0m: Wed Dec 18 23:42:59 2024 MSK\n",
      "\u001b[1mНазвание\u001b[0m: DummyUniform\n",
      "\u001b[1mОписание\u001b[0m: Тестовая загрузка данных базы 'Three bases'\n",
      "\u001b[1mСсылка\u001b[0m: \n",
      "\u001b[1mАвтор\u001b[0m: Moskalenko Viktor\n",
      "\n",
      "\u001b[1mМетрики\u001b[0m:\n",
      "                 1        2        3        4     7  micro avg  macro avg  \\\n",
      "precision 0.557996 0.957895 0.588845      0.5   0.0   0.575609   0.520947   \n",
      "recall    0.633478 0.061362 0.960061 0.001499   0.0   0.575256    0.33128   \n",
      "f1-score  0.593346 0.115336  0.72997  0.00299   0.0   0.575432   0.288328   \n",
      "support     5293.0   1483.0   3255.0    667.0 723.0    11421.0    11421.0   \n",
      "\n",
      "           weighted avg  samples avg  \n",
      "precision      0.580004     0.478549  \n",
      "recall         0.575256     0.468388  \n",
      "f1-score       0.498176     0.471775  \n",
      "support         11421.0      11421.0  \n",
      "\n",
      "\u001b[1mМатрицы рассогласования\u001b[0m:\n",
      "\n",
      "+-----------+----------+-----------+---------+---------+\n",
      "| 1         | 2        | 3         | 4       | 7       |\n",
      "+===========+==========+===========+=========+=========+\n",
      "| 5780 2656 | 12242  4 | 8292 2182 | 13061 1 | 13005 1 |\n",
      "| 1940 3353 |  1392 91 |  130 3125 |   666 1 |   723 0 |\n",
      "+-----------+----------+-----------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
